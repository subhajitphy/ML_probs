{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68845030-2851-4e68-988c-c649bdb18dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98efcfb3-e0c8-4e4d-b153-90f321b744bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "datadir = \"./\"\n",
    "\n",
    "# Load data\n",
    "data_tensor = torch.load(f\"{datadir}/data_test.pt\")  # Shape: (1_000_000, 7)\n",
    "\n",
    "# Split into inputs (first 5 columns) and outputs (last 2 columns)\n",
    "X_data = data_tensor[:, :5]  # Shape: (1_000_000, 5)\n",
    "Y_data= data_tensor[:, 5:]  # Shape: (1_000_000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "effba96f-4085-4970-9b5f-a7658183eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 5]), torch.Size([10000, 2]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape,Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5b4b0b9-ba8a-48ee-9b3e-1807ff563141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.7961,  2.9627],\n",
       "        [ 6.5094,  4.6870],\n",
       "        [23.4530,  7.9672],\n",
       "        ...,\n",
       "        [44.0922,  9.3547],\n",
       "        [14.0986,  5.5390],\n",
       "        [24.4505,  7.8674]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66aaa7a5-e0e5-48d5-b74b-795171e75951",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsun = 4.92549095e-6  # seconds\n",
    "\n",
    "def true_system(t, y, Mc, eta):\n",
    "    omega, phi = y\n",
    "    tN_omega = Mc * omega * tsun\n",
    "    d_omega = (96 / 5) * omega**2 * tN_omega**(5 / 3)\n",
    "    d_phi = omega\n",
    "    return [d_omega, d_phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd863d3b-a2c0-4790-b6bb-e8de40e670c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb62772c-294a-4240-a99d-f9fcb4a5ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Neural Network ====\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 2)  # outputs omega and phi\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91896bc7-7ca1-4d68-b3fc-2d0eed961439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(model, X_batch):\n",
    "    X_batch = X_batch.clone().detach().requires_grad_(True)\n",
    "\n",
    "    y_pred = model(X_batch)\n",
    "    omega_pred = y_pred[:, 0:1]\n",
    "    phi_pred = y_pred[:, 1:2]\n",
    "\n",
    "    t = X_batch[:, 0:1]\n",
    "    Mc = X_batch[:, 1:2]\n",
    "\n",
    "    tsun = 4.92549095e-6\n",
    "    tN_omega = Mc * omega_pred * tsun\n",
    "\n",
    "    d_omega = torch.autograd.grad(\n",
    "        outputs=omega_pred,\n",
    "        inputs=X_batch,\n",
    "        grad_outputs=torch.ones_like(omega_pred),\n",
    "        create_graph=True\n",
    "    )[0][:, 0:1]  # ∂ω/∂t\n",
    "\n",
    "    d_phi = torch.autograd.grad(\n",
    "        outputs=phi_pred,\n",
    "        inputs=X_batch,\n",
    "        grad_outputs=torch.ones_like(phi_pred),\n",
    "        create_graph=True\n",
    "    )[0][:, 0:1]  # ∂φ/∂t\n",
    "\n",
    "    res1 = d_omega - (96 / 5) * omega_pred**2 * tN_omega**(5 / 3)\n",
    "    res2 = d_phi - omega_pred\n",
    "\n",
    "    loss = (res1 ** 2).mean() + (res2 ** 2).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f051ac9-1d78-41e3-ac47-5bad6cbff56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ebb05b-59a8-4634-9692-87bd44e8df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = X_data.clone().detach().float().to(device) if isinstance(X_data, torch.Tensor) \\\n",
    "    else torch.tensor(X_data, dtype=torch.float32).to(device)\n",
    "dataset = TensorDataset(X_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = PINN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1ea79d-af52-46d6-a1f7-9efabd4227b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m optimizer.zero_grad()\n\u001b[32m      6\u001b[39m loss = physics_loss(model, X_batch)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m optimizer.step()\n\u001b[32m      9\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/ml_env/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/ml_env/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for (X_batch,) in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = physics_loss(model, X_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {total_loss/len(loader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480aaab-fcd4-4287-a83a-49597e2a3a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
